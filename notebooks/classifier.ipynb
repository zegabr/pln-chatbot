{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zegabr/pln-chatbot/blob/main/notebooks/classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd4HnUra57_U"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9RN7RtZlYsH"
      },
      "source": [
        "intent_mapper = {\n",
        "  'NEGATE': 0,\n",
        "  'NEGATE_INTENT': 1,\n",
        "  'REQUEST_ALTS': 2,\n",
        "  'GOODBYE': 3,\n",
        "  'REQUEST': 4,\n",
        "  'THANK_YOU': 5,\n",
        "  'AFFIRM': 6,\n",
        "  'AFFIRM_INTENT': 7,\n",
        "  'SELECT': 8,\n",
        "  'INFORM': 9,\n",
        "  'INFORM_INTENT': 10\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FsnnRKzRA4M"
      },
      "source": [
        "TRAIN_DATASET_PATH = 'https://raw.githubusercontent.com/zegabr/pln-chatbot/main/dataset/classification/train_dataset.csv'\n",
        "TEST_DATASET_PATH = 'https://raw.githubusercontent.com/zegabr/pln-chatbot/main/dataset/classification/test_dataset.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOD_AUX632j9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a741239-4a0f-45a3-d2ae-be70c1ed3a72"
      },
      "source": [
        "from pandas import read_csv\n",
        "train_restaurant_dataset = read_csv(TRAIN_DATASET_PATH)\n",
        "# pega 2 np arrays, um com as frases e outro com os respectivos intents\n",
        "train_dataset = train_restaurant_dataset.drop_duplicates(subset=['Phrase'])\n",
        "train_phrases = np.array(train_restaurant_dataset.Phrase)[1:]\n",
        "train_intents = np.array(train_restaurant_dataset.Intent.map(lambda x : intent_mapper[x]))[1:]\n",
        "print(train_phrases)\n",
        "print(train_intents)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['It has to be in San Fran.' \"It'll be afternoon 12.\" \"I'd like Palmer's.\"\n",
            " ... 'That sounds great! Thank you.' 'No, thank you very much!'\n",
            " 'No, thank you very much!']\n",
            "[9 9 9 ... 5 5 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlaYY2RsZTvY",
        "outputId": "ae9ed3fd-0527-4222-9a8e-6a57ae5299ef"
      },
      "source": [
        "test_dataset = read_csv(TEST_DATASET_PATH)\n",
        "# pega 2 np arrays, um com as frases e outro com os respectivos intents\n",
        "test_dataset = test_dataset.drop_duplicates(subset=['Phrase'])\n",
        "test_phrases = np.array(test_dataset.Phrase)[1:]\n",
        "test_intents = np.array(test_dataset.Intent.map(lambda x : intent_mapper[x]))[1:]\n",
        "\n",
        "print(test_phrases[:10])\n",
        "print(test_intents[:10])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Check in the San Jose area. I'd like to find a place that serves Diner style food.\"\n",
            " 'Great! can you make a reservation for one on Saturday this week?'\n",
            " 'For lunch at 12 in the afternoon.'\n",
            " 'On second thought, make it for Tuesday next week.'\n",
            " 'Yes. Also see if they have outdoor seating and what their rating is.'\n",
            " 'Great! Thank you.' \"No, thank you. I'm good for now.\"\n",
            " 'Can you help me find a place to eat?' \"I'm interested in Napa.\"\n",
            " \"Yes, I'm interested in Japanese.\"]\n",
            "[9 8 9 0 4 5 5 9 9 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAQo2_zVbAZI"
      },
      "source": [
        "VOCAB_SIZE = 2000\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_phrases)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtL0tz2wbeii",
        "outputId": "bda19668-ec0f-4d08-a508-419f24304ddb"
      },
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n",
        "print(len(encoder.get_vocabulary()))\n",
        "vocab[:20]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'i', 'for', 'the', 'a', 'to', 'you', 'that', 'is',\n",
              "       'in', 'yes', 'make', 'it', 'at', 'reservation', 'me', 'restaurant',\n",
              "       'no', 'thats'], dtype='<U15')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nigIW3OJxUqh"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  encoder,\n",
        "  tf.keras.layers.Embedding(\n",
        "    input_dim=len(encoder.get_vocabulary()),\n",
        "    output_dim=64,\n",
        "    # Use masking to handle the variable sequence lengths\n",
        "    mask_zero=True),\n",
        "  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "  tf.keras.layers.Dense(11, activation='softmax')\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8PxfkXjdASW",
        "outputId": "7d720f7d-50cb-4f98-fb24-07db8c2726f4"
      },
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = ('Alright, fine. Now I would like to find a one-way flight to go '\n",
        "               'there, and I do not mind which airline I will have.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.09223935 0.09036412 0.08944915 0.09126627 0.09156563 0.090437\n",
            " 0.0910646  0.0907815  0.09133977 0.0908443  0.09064839]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee8vuMVrdX_4",
        "outputId": "ddc51bec-f40f-4dd5-baa0-30b4e8d5e334"
      },
      "source": [
        "# predict on a sample text with padding\n",
        "\n",
        "padding = \"the \" * 2000\n",
        "predictions = model.predict(np.array([sample_text, padding]))\n",
        "print(predictions[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.09223935 0.09036412 0.08944915 0.09126627 0.09156563 0.090437\n",
            " 0.0910646  0.0907815  0.09133977 0.0908443  0.09064839]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG-G98EsdavD"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkGnDIAadiOw",
        "outputId": "da01a323-cabb-4081-8771-860a34160c3f"
      },
      "source": [
        "history = model.fit(train_phrases, train_intents, epochs=20)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "112/112 [==============================] - 10s 28ms/step - loss: 2.3352 - accuracy: 0.3751\n",
            "Epoch 2/20\n",
            "112/112 [==============================] - 3s 30ms/step - loss: 1.9082 - accuracy: 0.4102\n",
            "Epoch 3/20\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 1.6934 - accuracy: 0.4228\n",
            "Epoch 4/20\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 1.5413 - accuracy: 0.5093\n",
            "Epoch 5/20\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 1.3768 - accuracy: 0.6058\n",
            "Epoch 6/20\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 1.2479 - accuracy: 0.6420\n",
            "Epoch 7/20\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 1.1449 - accuracy: 0.6574\n",
            "Epoch 8/20\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 1.0542 - accuracy: 0.6639\n",
            "Epoch 9/20\n",
            "112/112 [==============================] - 3s 27ms/step - loss: 0.9778 - accuracy: 0.6686\n",
            "Epoch 10/20\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 0.9135 - accuracy: 0.6712\n",
            "Epoch 11/20\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 0.8649 - accuracy: 0.6762\n",
            "Epoch 12/20\n",
            "112/112 [==============================] - 3s 31ms/step - loss: 0.8246 - accuracy: 0.6765\n",
            "Epoch 13/20\n",
            "112/112 [==============================] - 3s 30ms/step - loss: 0.7896 - accuracy: 0.6785\n",
            "Epoch 14/20\n",
            "112/112 [==============================] - 3s 29ms/step - loss: 0.7610 - accuracy: 0.6827\n",
            "Epoch 15/20\n",
            "112/112 [==============================] - 3s 31ms/step - loss: 0.7347 - accuracy: 0.6869\n",
            "Epoch 16/20\n",
            "112/112 [==============================] - 3s 28ms/step - loss: 0.7137 - accuracy: 0.6930\n",
            "Epoch 17/20\n",
            "112/112 [==============================] - 3s 31ms/step - loss: 0.6939 - accuracy: 0.6914\n",
            "Epoch 18/20\n",
            "112/112 [==============================] - 3s 30ms/step - loss: 0.6768 - accuracy: 0.6944\n",
            "Epoch 19/20\n",
            "112/112 [==============================] - 3s 30ms/step - loss: 0.6621 - accuracy: 0.6998\n",
            "Epoch 20/20\n",
            "112/112 [==============================] - 3s 27ms/step - loss: 0.6475 - accuracy: 0.7009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q043eZ2-jY_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "276c5e35-f53b-41f4-9471-569f113d0a89"
      },
      "source": [
        "sample_test = ('I\\'m looking for a restaurant, can you help?')\n",
        "sample_test_intent = 'INFORM'\n",
        "predictions = model.predict(np.array([sample_test]))\n",
        "for i in predictions:\n",
        "  for idx, intent in enumerate(i):\n",
        "    print('{:.2f}%'.format(intent*100), [i for i in intent_mapper.keys()][idx])\n",
        "print('uhu?')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13.57% NEGATE\n",
            "0.00% NEGATE_INTENT\n",
            "0.47% REQUEST_ALTS\n",
            "0.00% GOODBYE\n",
            "0.05% REQUEST\n",
            "0.09% THANK_YOU\n",
            "0.30% AFFIRM\n",
            "0.00% AFFIRM_INTENT\n",
            "0.62% SELECT\n",
            "84.90% INFORM\n",
            "0.00% INFORM_INTENT\n",
            "uhu?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2g6TZaYCI-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c7956b5-644b-409e-917d-6e02c8bf1fd7"
      },
      "source": [
        "sample_test = ('Also see if they have outdoor seating and what their rating is')\n",
        "sample_test_intent = 'REQUEST'\n",
        "predictions = model.predict(np.array([sample_test]))\n",
        "for i in predictions:\n",
        "  for idx, intent in enumerate(i):\n",
        "    print('{:.2f}%'.format(intent*100), [i for i in intent_mapper.keys()][idx])\n",
        "print('uhu?')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.01% NEGATE\n",
            "0.00% NEGATE_INTENT\n",
            "0.05% REQUEST_ALTS\n",
            "0.00% GOODBYE\n",
            "74.26% REQUEST\n",
            "0.01% THANK_YOU\n",
            "25.42% AFFIRM\n",
            "0.00% AFFIRM_INTENT\n",
            "0.21% SELECT\n",
            "0.04% INFORM\n",
            "0.00% INFORM_INTENT\n",
            "uhu?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8d-oORC6iPP",
        "outputId": "10fbb0ae-49bb-4fbb-acd3-2e2fe7a10827"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "test_phrases = np.array(test_dataset.Phrase)[1:]\n",
        "test_intents = np.array(test_dataset.Intent.map(lambda x : intent_mapper[x]))[1:]\n",
        "\n",
        "predictions = model.predict(np.array(test_phrases))\n",
        "y_pred = [] \n",
        "for pred in predictions:\n",
        "  y_pred.append(pred.argmax())\n",
        "\n",
        "print(classification_report(test_intents, y_pred, zero_division = 1))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.35      0.33        20\n",
            "           2       0.67      0.46      0.55        13\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.95      0.68      0.79        82\n",
            "           5       0.90      0.78      0.84        97\n",
            "           6       0.57      0.68      0.62        65\n",
            "           8       0.55      0.15      0.24        40\n",
            "           9       0.79      0.99      0.88       200\n",
            "\n",
            "    accuracy                           0.76       517\n",
            "   macro avg       0.59      0.51      0.53       517\n",
            "weighted avg       0.77      0.76      0.75       517\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.35      0.33        20\n",
            "           2       0.67      0.46      0.55        13\n",
            "           3       0.00      1.00      0.00         0\n",
            "           4       0.95      0.68      0.79        82\n",
            "           5       0.90      0.78      0.84        97\n",
            "           6       0.57      0.68      0.62        65\n",
            "           8       0.55      0.15      0.24        40\n",
            "           9       0.79      0.99      0.88       200\n",
            "\n",
            "    accuracy                           0.76       517\n",
            "   macro avg       0.59      0.64      0.53       517\n",
            "weighted avg       0.77      0.76      0.75       517\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}