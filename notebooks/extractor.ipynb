{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extractor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYZuFGpnbdXAP+qVJ0wYS4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zegabr/pln-chatbot/blob/main/notebooks/extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QZE-wdmtIUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e726e5fe-2ed5-4a1d-e4c6-fccdc106385e"
      },
      "source": [
        "#http://alexminnaar.com/2019/08/22/ner-rnns-tensorflow.html\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from pandas import read_csv\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCXqemmeu6OV"
      },
      "source": [
        "TRAIN_DATASET_PATH = 'https://raw.githubusercontent.com/zegabr/pln-chatbot/main/dataset/extraction/train_dataset.csv'\n",
        "TEST_DATASET_PATH = 'https://raw.githubusercontent.com/zegabr/pln-chatbot/main/dataset/extraction/test_dataset.csv'\n",
        "VALID_DATASET_PATH = 'https://raw.githubusercontent.com/zegabr/pln-chatbot/main/dataset/extraction/dev_dataset.csv'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBUIs_B_2Ejo",
        "outputId": "3e3ac7e2-545f-4142-8f44-c18d179ee382"
      },
      "source": [
        "train_dataset = read_csv(TRAIN_DATASET_PATH)[:-1]\n",
        "test_dataset = read_csv(TEST_DATASET_PATH)[:-1]\n",
        "valid_dataset = read_csv(VALID_DATASET_PATH)[:-1]\n",
        "print(train_dataset)\n",
        "print(test_dataset)\n",
        "print(valid_dataset)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Phrase Entity\n",
            "0                I      O\n",
            "1             need      O\n",
            "2                a      O\n",
            "3       restaurant      O\n",
            "4      reservation      O\n",
            "...            ...    ...\n",
            "32532        thank      O\n",
            "32533          you      O\n",
            "32534         very      O\n",
            "32535         much      O\n",
            "32536            !      O\n",
            "\n",
            "[32537 rows x 2 columns]\n",
            "          Phrase Entity\n",
            "0              I      O\n",
            "1             'm      O\n",
            "2        looking      O\n",
            "3            for      O\n",
            "4              a      O\n",
            "...          ...    ...\n",
            "6366           .      O\n",
            "6367      Really      O\n",
            "6368  appreciate      O\n",
            "6369          it      O\n",
            "6370           !      O\n",
            "\n",
            "[6371 rows x 2 columns]\n",
            "      Phrase Entity\n",
            "0         Do      O\n",
            "1        you      O\n",
            "2       know      O\n",
            "3         of      O\n",
            "4        any      O\n",
            "...      ...    ...\n",
            "7085       .      O\n",
            "7086  Thanks      O\n",
            "7087      so      O\n",
            "7088    much      O\n",
            "7089       .      O\n",
            "\n",
            "[7090 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuppFGNd3dTP",
        "outputId": "f69411b1-62f4-45b4-81b7-25da5da96dfb"
      },
      "source": [
        "from pandas import notna\n",
        "\n",
        "labels = set()\n",
        "\n",
        "def to_examples(dataset):\n",
        "  examples=[]\n",
        "  example = [[],[]]\n",
        "  for idx, row in dataset.iterrows():\n",
        "    phrase, entity = row['Phrase'], row['Entity']\n",
        "    if notna(phrase) and notna(entity):\n",
        "      example[0].append(phrase)\n",
        "      example[1].append(entity)\n",
        "      labels.add(entity)\n",
        "    else:\n",
        "      examples.append(example)\n",
        "      example=[[],[]]\n",
        "  return examples\n",
        "\n",
        "train_examples = to_examples(train_dataset)\n",
        "test_examples = to_examples(test_dataset)\n",
        "valid_examples = to_examples(valid_dataset)\n",
        "print(train_examples[:10])\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[['I', 'need', 'a', 'restaurant', 'reservation', '.'], ['O', 'O', 'O', 'O', 'O', 'O']], [['It', 'has', 'to', 'be', 'in', 'San', 'Fran', '.'], ['O', 'O', 'O', 'O', 'O', 'B-city', 'I-city', 'O']], [['It', \"'ll\", 'be', 'afternoon', '12', '.'], ['O', 'O', 'O', 'B-time', 'I-time', 'O']], [['I', \"'d\", 'like', 'Palmer', \"'s\", '.'], ['O', 'O', 'O', 'B-restaurant_name', 'I-restaurant_name', 'O']], [['Perfect', '.', 'What', \"'s\", 'their', 'cuisine', 'type', 'and', 'number', '?'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']], [['Thanks', ',', 'a', 'lot', '.', 'That', \"'ll\", 'do', 'it', ',', 'for', 'now', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']], [['On', 'March', '2nd', 'we', 'are', 'going', 'to', 'celebrate', 'my', 'wedding', 'anniversary', '.', 'So', 'please', 'check', 'for', 'a', 'reservation', 'at', 'a', 'restaurant', '.'], ['O', 'B-date', 'I-date', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']], [['Yes', ',', 'I', 'prefer', 'jannah', 'restaurant', 'at', '4:30', 'pm'], ['O', 'O', 'O', 'O', 'B-restaurant_name', 'O', 'O', 'B-time', 'I-time']], [['It', 'must', 'be', 'in', 'SFO'], ['O', 'O', 'O', 'O', 'B-city']], [['Sorry', ',', 'Please', 'change', 'it', 'the', '8th', 'at', '11:30'], ['O', 'O', 'O', 'O', 'O', 'B-date', 'I-date', 'O', 'B-time']]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B03KHX-k7KDc",
        "outputId": "f2947fce-cf39-4a61-e04a-c989fe5f5e18"
      },
      "source": [
        "    # create character vocab\n",
        "    all_text = \" \".join([\" \".join(x[0]) for x in train_examples+valid_examples+test_examples])\n",
        "    vocab = sorted(set(all_text))\n",
        "    \n",
        "    # create character/id and label/id mapping\n",
        "    char2idx = {u:i+1 for i, u in enumerate(vocab)}\n",
        "    idx2char = np.array(vocab)\n",
        "    label2idx = {u:i+1 for i, u in enumerate(labels)}\n",
        "    idx2label = np.array(labels)\n",
        "    \n",
        "    print(idx2label)\n",
        "    print(char2idx)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'I-cuisine', 'B-city', 'B-location', 'B-restaurant_name', 'I-restaurant_name', 'I-price_range', 'B-price_range', 'I-category', 'B-party_size', 'I-location', 'I-date', 'I-city', 'B-time', 'B-cuisine', 'B-date', 'B-number_of_seats', 'O', 'B-category', 'I-time'}\n",
            "{' ': 1, '!': 2, '&': 3, \"'\": 4, ',': 5, '-': 6, '.': 7, '/': 8, '0': 9, '1': 10, '2': 11, '3': 12, '4': 13, '5': 14, '6': 15, '7': 16, '8': 17, '9': 18, ':': 19, ';': 20, '?': 21, 'A': 22, 'B': 23, 'C': 24, 'D': 25, 'E': 26, 'F': 27, 'G': 28, 'H': 29, 'I': 30, 'J': 31, 'K': 32, 'L': 33, 'M': 34, 'N': 35, 'O': 36, 'P': 37, 'Q': 38, 'R': 39, 'S': 40, 'T': 41, 'U': 42, 'V': 43, 'W': 44, 'Y': 45, 'Z': 46, '`': 47, 'a': 48, 'b': 49, 'c': 50, 'd': 51, 'e': 52, 'f': 53, 'g': 54, 'h': 55, 'i': 56, 'j': 57, 'k': 58, 'l': 59, 'm': 60, 'n': 61, 'o': 62, 'p': 63, 'q': 64, 'r': 65, 's': 66, 't': 67, 'u': 68, 'v': 69, 'w': 70, 'x': 71, 'y': 72, 'z': 73}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9zwEFJc7Quj",
        "outputId": "ea2ca0f6-6b91-4a31-e733-f3008004f714"
      },
      "source": [
        "    def split_char_labels(eg):\n",
        "      '''\n",
        "      For a given input/output example, break tokens into characters while keeping \n",
        "      the same label.\n",
        "      '''\n",
        "\n",
        "      tokens = eg[0]\n",
        "      labels=eg[1]\n",
        "\n",
        "      input_chars = []\n",
        "      output_char_labels = []\n",
        "\n",
        "      for token,label in zip(tokens,labels):\n",
        "\n",
        "        input_chars.extend([char for char in token])\n",
        "        input_chars.extend(' ')\n",
        "        output_char_labels.extend([label]*len(token))\n",
        "        output_char_labels.extend('O')\n",
        "\n",
        "      return [[char2idx[x] for x in input_chars[:-1]],np.array([label2idx[x] for x in output_char_labels[:-1]])]\n",
        "   \n",
        "    train_formatted = [split_char_labels(eg) for eg in train_examples]\n",
        "    test_formatted = [split_char_labels(eg) for eg in test_examples]\n",
        "    valid_formatted = [split_char_labels(eg) for eg in valid_examples]\n",
        "    \n",
        "    print(len(train_formatted))\n",
        "    print(len(test_formatted))\n",
        "    print(len(valid_formatted))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2975\n",
            "532\n",
            "626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCn7BpKz7WV2",
        "outputId": "317d44a0-22a4-40e1-e2b8-12a04db2bfda"
      },
      "source": [
        "    # training generator\n",
        "    def gen_train_series():\n",
        "\n",
        "        for eg in train_formatted:\n",
        "          yield eg[0],eg[1]\n",
        "    \n",
        "    # validation generator\n",
        "    def gen_valid_series():\n",
        "    \n",
        "       for eg in valid_formatted:\n",
        "          yield eg[0],eg[1]\n",
        "    \n",
        "    # test generator\n",
        "    def gen_test_series():\n",
        "\n",
        "      for eg in test_formatted:\n",
        "          yield eg[0],eg[1]\n",
        "      \n",
        "    # create Dataset objects for train, test and validation sets  \n",
        "    series = tf.data.Dataset.from_generator(gen_train_series,output_types=(tf.int32, tf.int32),output_shapes = ((None, None)))\n",
        "    series_valid = tf.data.Dataset.from_generator(gen_valid_series,output_types=(tf.int32, tf.int32),output_shapes = ((None, None)))\n",
        "    series_test = tf.data.Dataset.from_generator(gen_test_series,output_types=(tf.int32, tf.int32),output_shapes = ((None, None)))\n",
        "\n",
        "    BATCH_SIZE = 128\n",
        "    BUFFER_SIZE=1000\n",
        "    \n",
        "    # create padded batch series objects for train, test and validation sets\n",
        "    ds_series_batch = series.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE, padded_shapes=([None], [None]), drop_remainder=True)\n",
        "    ds_series_batch_valid = series_valid.padded_batch(BATCH_SIZE, padded_shapes=([None], [None]), drop_remainder=True)\n",
        "    ds_series_batch_test = series_test.padded_batch(BATCH_SIZE, padded_shapes=([None], [None]), drop_remainder=True)\n",
        "    \n",
        "    # print example batches\n",
        "    for input_example_batch, target_example_batch in ds_series_batch_valid.take(1):\n",
        "      print(input_example_batch)\n",
        "      print(target_example_batch)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[25 62  1 ...  0  0  0]\n",
            " [30  1  4 ...  0  0  0]\n",
            " [45 52 48 ...  0  0  0]\n",
            " ...\n",
            " [41 55 48 ...  0  0  0]\n",
            " [30  1  4 ...  0  0  0]\n",
            " [30 61  1 ...  0  0  0]], shape=(128, 132), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[17 17 17 ...  0  0  0]\n",
            " [17 17 17 ...  0  0  0]\n",
            " [17 17 17 ...  0  0  0]\n",
            " ...\n",
            " [17 17 17 ...  0  0  0]\n",
            " [17 17 17 ...  0  0  0]\n",
            " [17 17 17 ...  0  0  0]], shape=(128, 132), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGihVDEA7Y92",
        "outputId": "2913310e-79ae-4399-ec28-adc8dd6c0dec"
      },
      "source": [
        "  vocab_size = len(vocab)+1\n",
        "\n",
        "  # The embedding dimension\n",
        "  embedding_dim = 256\n",
        "\n",
        "  # Number of RNN units\n",
        "  rnn_units = 1024\n",
        "\n",
        "  label_size = len(labels)  \n",
        "  \n",
        "  # build LSTM model\n",
        "  def build_model(vocab_size,label_size, embedding_dim, rnn_units, batch_size):\n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None],mask_zero=True),\n",
        "            tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "            tf.keras.layers.Dense(label_size)\n",
        "            ])\n",
        "        return model\n",
        "\n",
        "  model = build_model(\n",
        "        vocab_size = len(vocab)+1,\n",
        "        label_size=len(labels)+1,\n",
        "        embedding_dim=embedding_dim,\n",
        "        rnn_units=rnn_units,\n",
        "        batch_size=BATCH_SIZE)\n",
        "\n",
        "  model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (128, None, 256)          18944     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (128, None, 1024)         5246976   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (128, None, 20)           20500     \n",
            "=================================================================\n",
            "Total params: 5,286,420\n",
            "Trainable params: 5,286,420\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQEhbW-Q7c5Y"
      },
      "source": [
        "    import os\n",
        "\n",
        "    # define loss function\n",
        "    def loss(labels, logits):\n",
        "        return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=loss,\n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "    # Directory where the checkpoints will be saved\n",
        "    checkpoint_dir = './training_checkpoints'\n",
        "    # Name of the checkpoint files\n",
        "    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "    checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_prefix,\n",
        "        save_weights_only=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcxEcIzB7gjl",
        "outputId": "c7a99eb0-2e56-4707-ed23-ef0c29039c1a"
      },
      "source": [
        "    EPOCHS=20\n",
        "    history = model.fit(ds_series_batch,\n",
        "                        epochs=EPOCHS,\n",
        "                        validation_data=ds_series_batch_valid,\n",
        "                        callbacks=[checkpoint_callback])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "23/23 [==============================] - 388s 17s/step - loss: 0.2930 - sparse_categorical_accuracy: 0.8573 - val_loss: 0.2306 - val_sparse_categorical_accuracy: 0.8938\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 374s 16s/step - loss: 0.1951 - sparse_categorical_accuracy: 0.8862 - val_loss: 0.2282 - val_sparse_categorical_accuracy: 0.8938\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 371s 16s/step - loss: 0.1774 - sparse_categorical_accuracy: 0.8893 - val_loss: 0.2469 - val_sparse_categorical_accuracy: 0.8932\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 368s 16s/step - loss: 0.1712 - sparse_categorical_accuracy: 0.8930 - val_loss: 0.2008 - val_sparse_categorical_accuracy: 0.9000\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 382s 17s/step - loss: 0.1435 - sparse_categorical_accuracy: 0.8945 - val_loss: 0.1934 - val_sparse_categorical_accuracy: 0.9001\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 373s 16s/step - loss: 0.1338 - sparse_categorical_accuracy: 0.8999 - val_loss: 0.1907 - val_sparse_categorical_accuracy: 0.8967\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 381s 17s/step - loss: 0.1155 - sparse_categorical_accuracy: 0.9095 - val_loss: 0.1868 - val_sparse_categorical_accuracy: 0.8995\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 359s 16s/step - loss: 0.1098 - sparse_categorical_accuracy: 0.9149 - val_loss: 0.1905 - val_sparse_categorical_accuracy: 0.9035\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 373s 16s/step - loss: 0.0978 - sparse_categorical_accuracy: 0.9240 - val_loss: 0.1783 - val_sparse_categorical_accuracy: 0.9159\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 368s 16s/step - loss: 0.0905 - sparse_categorical_accuracy: 0.9280 - val_loss: 0.1833 - val_sparse_categorical_accuracy: 0.9104\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 368s 16s/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9358 - val_loss: 0.1712 - val_sparse_categorical_accuracy: 0.9204\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 365s 16s/step - loss: 0.0721 - sparse_categorical_accuracy: 0.9433 - val_loss: 0.1751 - val_sparse_categorical_accuracy: 0.9222\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 360s 15s/step - loss: 0.0658 - sparse_categorical_accuracy: 0.9483 - val_loss: 0.1729 - val_sparse_categorical_accuracy: 0.9253\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 370s 16s/step - loss: 0.0582 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1696 - val_sparse_categorical_accuracy: 0.9295\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 371s 16s/step - loss: 0.0526 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.1679 - val_sparse_categorical_accuracy: 0.9328\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 369s 16s/step - loss: 0.0490 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.1730 - val_sparse_categorical_accuracy: 0.9289\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 373s 16s/step - loss: 0.0447 - sparse_categorical_accuracy: 0.9631 - val_loss: 0.1690 - val_sparse_categorical_accuracy: 0.9338\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 359s 16s/step - loss: 0.0433 - sparse_categorical_accuracy: 0.9658 - val_loss: 0.1677 - val_sparse_categorical_accuracy: 0.9363\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 372s 16s/step - loss: 0.0403 - sparse_categorical_accuracy: 0.9660 - val_loss: 0.1680 - val_sparse_categorical_accuracy: 0.9326\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 377s 16s/step - loss: 0.0355 - sparse_categorical_accuracy: 0.9696 - val_loss: 0.1716 - val_sparse_categorical_accuracy: 0.9347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wRIQHj77ol8",
        "outputId": "3543d79b-9cb3-414a-83f4-05db103b28d0"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "preds = np.array([])\n",
        "y_trues= np.array([])\n",
        "\n",
        "# iterate through test set, make predictions based on trained model\n",
        "for input_example_batch, target_example_batch in ds_series_batch_test:\n",
        "\n",
        "  pred=model.predict_on_batch(input_example_batch)\n",
        "  pred_max=tf.argmax(tf.nn.softmax(pred),2).numpy().flatten()\n",
        "  y_true=target_example_batch.numpy().flatten()\n",
        "\n",
        "  preds=np.concatenate([preds,pred_max])\n",
        "  y_trues=np.concatenate([y_trues,y_true])\n",
        "\n",
        "# remove padding from evaluation\n",
        "remove_padding = [(p,y) for p,y in zip(preds,y_trues) if y!=0]\n",
        "\n",
        "r_p = [x[0] for x in remove_padding]\n",
        "r_t = [x[1] for x in remove_padding]\n",
        "\n",
        "# print confusion matrix and classification report\n",
        "print(confusion_matrix(r_p,r_t))\n",
        "print(classification_report(r_p,r_t))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    0     0     0     0     9     0     0    24     0     0     1     0\n",
            "      0     0     0     0     9     0     0]\n",
            " [    0     0   362     7     0     0     0     0     0     0     0     0\n",
            "      0     0     7     0     4    12     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [    0     0     0    60     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     3    13     0]\n",
            " [    0     0     0     0    76     0     0     8     0     4     0     0\n",
            "      0     0     0     0     8     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [    0     0     0     1     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     1     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      5     0     1    13     1     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     2     0     0     0     0     0   160     0\n",
            "      0     0     3     0    15     0     2]\n",
            " [    0     0     4     0     7     0     0     0     0   165     0     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [    0     0     0     1     1     0     0     0     0     0     0     0\n",
            "    274     0     3     8    11     0     5]\n",
            " [    0     0    10    70     0     0     0     0     0     0     0     0\n",
            "      0     0     6     0    19   224     0]\n",
            " [    0     0     0    12     0     0     0     0     0     0    16     0\n",
            "      0     0    77     0     2     0     3]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [    0     0    14    35    11     8    61     9     0     9     8     0\n",
            "     79     0    36     0 21924    52    66]\n",
            " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     1     0     0     0     0     0     0     0\n",
            "      0     0     1     0     6     0   574]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.00      0.00      0.00        43\n",
            "         2.0       0.00      0.00      0.00       392\n",
            "         3.0       0.00      0.00      0.00         0\n",
            "         4.0       0.32      0.79      0.46        76\n",
            "         5.0       0.71      0.79      0.75        96\n",
            "         6.0       0.00      0.00      0.00         0\n",
            "         7.0       0.00      0.00      0.00         2\n",
            "         8.0       0.00      0.00      0.00         0\n",
            "         9.0       0.00      0.00      0.00        20\n",
            "        10.0       0.00      0.00      0.00         0\n",
            "        11.0       0.86      0.88      0.87       182\n",
            "        12.0       0.00      0.00      0.00       176\n",
            "        13.0       0.77      0.90      0.83       303\n",
            "        14.0       0.00      0.00      0.00       329\n",
            "        15.0       0.57      0.70      0.63       110\n",
            "        16.0       0.00      0.00      0.00         0\n",
            "        17.0       1.00      0.98      0.99     22312\n",
            "        18.0       0.00      0.00      0.00         0\n",
            "        19.0       0.88      0.99      0.93       582\n",
            "\n",
            "    accuracy                           0.94     24623\n",
            "   macro avg       0.27      0.32      0.29     24623\n",
            "weighted avg       0.95      0.94      0.94     24623\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}