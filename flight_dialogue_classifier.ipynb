{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "z√©'s Copy of ze's Copy of restaurant_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zegabr/pln-chatbot/blob/main/flight_dialogue_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd4HnUra57_U"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOD_AUX632j9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cde46402-788b-4252-e525-c9ba0d8b907c"
      },
      "source": [
        "from pandas import read_csv\n",
        "\n",
        "train_dataset = read_csv('https://raw.githubusercontent.com/zegabr/pln-chatbot/main/train_dataset.csv', names=['Phrase', 'Intent'])\n",
        "train_dataset = train_dataset.drop_duplicates(subset=['Phrase'])\n",
        "# pega 2 np arrays, um com as frases e outro com os respectivos intents\n",
        "train_phrases = np.array(train_dataset.Phrase)[1:]\n",
        "train_intents = np.array(train_dataset.Intent)[1:]\n",
        "print(train_phrases)\n",
        "\n",
        "test_dataset = read_csv('https://raw.githubusercontent.com/zegabr/pln-chatbot/main/test_dataset.csv', names=['Phrase', 'Intent'])\n",
        "test_dataset = test_dataset.drop_duplicates(subset=['Phrase'])\n",
        "# pega 2 np arrays, um com as frases e outro com os respectivos intents\n",
        "test_phrases = np.array(test_dataset.Phrase)[1:]\n",
        "test_intents = np.array(test_dataset.Intent)[1:]\n",
        "print(test_intents)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I need a one way flight and prefer traveling in Premium Economy class.'\n",
            " 'I would like to leave next Friday.'\n",
            " 'I am traveling to NYC from Seattle, WA. I prefer to travel on Delta Airlines.'\n",
            " ... 'Can you search other flights'\n",
            " \"I'll be back March 12th, economy preferred\"\n",
            " \"That's good, thats all thanks\"]\n",
            "['INFORM' 'INFORM' 'INFORM' ... 'INFORM' 'REQUEST' 'SELECT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO5Ucl0t7rD2",
        "outputId": "225477c2-01a2-4d04-dfd1-fb10b6265a42"
      },
      "source": [
        "intent_mapper = {\n",
        "  'NEGATE': 0,\n",
        "  'NEGATE_INTENT': 1,\n",
        "  'REQUEST_ALTS': 2,\n",
        "  'GOODBYE': 3,\n",
        "  'REQUEST': 4,\n",
        "  'THANK_YOU': 5,\n",
        "  'AFFIRM': 6,\n",
        "  'AFFIRM_INTENT': 7,\n",
        "  'SELECT': 8,\n",
        "  'INFORM': 9,\n",
        "  'INFORM_INTENT': 10\n",
        "}\n",
        "train_intents_encoded = np.array(list(map(lambda x: intent_mapper[x],train_intents)))\n",
        "print(train_intents_encoded)\n",
        "test_intents_encoded = np.array(list(map(lambda x: intent_mapper[x],test_intents)))\n",
        "print(test_intents_encoded)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 9 9 ... 9 9 8]\n",
            "[9 9 9 ... 9 4 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJJDZ26vIp48",
        "outputId": "8a2f3e66-8a6a-443e-cda3-2e046c544858"
      },
      "source": [
        "# one hot encoding pra train phrases (feito artesanalmente)\n",
        "def get_one_hot_encoding(train_phrases, test_phrases):\n",
        "  max_phrase_size = 0\n",
        "  # map words to numbers\n",
        "  word_to_number = {}\n",
        "  curr = 1\n",
        "  all_phrases = np.concatenate((train_phrases, test_phrases))\n",
        "  for phrase in all_phrases:\n",
        "    max_phrase_size = max(max_phrase_size,len(phrase.split()))\n",
        "    for word in phrase.split():\n",
        "      if word not in word_to_number:\n",
        "        word_to_number[word] = curr\n",
        "        curr += 1\n",
        "  \n",
        "  # map train_phrases to vectors of numbers\n",
        "  one_hotted_train = []\n",
        "  for phrase in train_phrases:\n",
        "    curr_vector = []\n",
        "    for word in phrase.split():\n",
        "      curr_vector.append(word_to_number[word])\n",
        "    # add zero as padding\n",
        "    while len(curr_vector) < max_phrase_size:\n",
        "      curr_vector.append(0)\n",
        "    one_hotted_train.append(curr_vector)\n",
        "  \n",
        "  # map test to vectors of numbers\n",
        "  one_hotted_test = []\n",
        "  for phrase in test_phrases:\n",
        "    curr_vector = []\n",
        "    for word in phrase.split():\n",
        "      curr_vector.append(word_to_number[word])\n",
        "    # add zero as padding\n",
        "    while len(curr_vector) < max_phrase_size:\n",
        "      curr_vector.append(0)\n",
        "    one_hotted_test.append(curr_vector)\n",
        "  \n",
        "  #return nparray\n",
        "  return np.array(one_hotted_train), np.array(one_hotted_test)\n",
        "\n",
        "train_phrases_encoded, test_phrases_encoded = get_one_hot_encoding(train_phrases, test_phrases)\n",
        "train_phrases_encoded"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1,   2,   3, ...,   0,   0,   0],\n",
              "       [  1,  14,  15, ...,   0,   0,   0],\n",
              "       [  1,  20,   9, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [ 42,  43, 321, ...,   0,   0,   0],\n",
              "       [ 62,  63, 311, ...,   0,   0,   0],\n",
              "       [ 92, 290, 319, ...,   0,   0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnVbTZBUN3Op",
        "outputId": "40286c54-ade4-452d-b4f8-98f46e6e25d3"
      },
      "source": [
        "# criando modelo com random forest\n",
        "# codigo pego daqui https://colab.research.google.com/github/ProfLuciano/cd/blob/gh-pages/notebooks/classification.ipynb#scrollTo=ekLczfhAeLh5\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=1000)\n",
        "model.fit(train_phrases_encoded, train_intents_encoded)\n",
        "ypred_test = model.predict(test_phrases_encoded)\n",
        "ypred_train = model.predict(train_phrases_encoded)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"ACC TRAINING:\" + str(accuracy_score(train_intents_encoded, ypred_train)))\n",
        "print(\"ACC TEST:\" + str(accuracy_score(test_intents_encoded, ypred_test)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACC TRAINING:1.0\n",
            "ACC TEST:0.7335203366058906\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}